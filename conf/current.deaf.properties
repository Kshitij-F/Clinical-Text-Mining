#  ############# UMLS term matching configuration #####################3
#  # jdbcDriver is the database url that uses for extern info for a term in UMLS. e.g. selecting TUI by CUI from the table MRSTY.
#  # for now, table mrstr is neccessary
jdbcDriver=jdbc:mysql://somelab12.cci.fsu.edu:3306/umls?user=root&password=root

useStanfordNLP=true
#lvgdir=/data/ra/lvg2015/
# split the text into block before sentence segmentation. For clinical trials
textBlockDelimiter=#|\\n
# Special segmentation of the text before sentence segmentation (':', ' - ', 'Or|OR', 'No', 'At'). For clinical trials
textBlockDelimiterSpecialEnable=true


#  # 0 - 100. if the similarity score for a ngram is greater than this threshold, the ngran will be consider as umls term
umlsLikehoodLimit=80
#  # the window length to fetch context of a ngram

#################  Metamap configuration ##########################
MMenable=true
# output option have to implement by yourself. don't use as a option.
# -J (--restrict_to_sts) <list>  -e (--exclude_sources) <list>  -R (--restrict_to_sources) <list>
MMoptions=--allow_concept_gaps -R CHV -y 
#MMoptions=--allow_concept_gaps -R SNOMEDCT_US -y
MMscoreThreshold = 800
MMhost=
MMport=
# only perform metamap parsing.
MMonly=true

################# end Metamap configuration #######################

#######################################################################
############### Ngram relative configuration ###################################
# the threshold of tf when fetch ngram in partition
partitionTfFilter=2
# the threshold of tf when fetch ngram in first stage
stag1TfFilter=2
stag1CvalueFilter=1
# the threshold of tf when fetch ngram in second stage
stag2TfFilter=5
stag2CvalueFilter=1
# the thresholh of umls/chv score. no filter if it is -1
stag2UmlsScoreFilter=-1
stag2ChvScoreFilter=-1


######################## bags of words configuration ##############
bagsOfWord=false
bowUmlsOnly=false
bowTfFilter=100
# maximum number of bag of words
bowTopNgram=10000
bowDialogSetOne=false
######################## end of bags of words configuration ######

########################################################################
############## Clustering relative configuration ##########################
## Nlp do not allow multi-thread, so you can not use local[N] for generating Ngram, but you can use it to run kmeans
#sparkMaster=local[2]
#partitionNumber=8
############ only use chv term as trainig data
#trainOnlyChv=true
## filter the ngran before run kmeans (remove the matched item)
#trainedNgramFilterPosRegex=[^N]*PN
## how many percent of the data is sample as test data(for evaluation), <= 0, no thing is test
#testSample=30
#sampleRuns=1
##number of ngram for training. For test purpose. <0: no limit;
#trainNgramCnt=-1
#
## PCA only. Compact the feature space matrix to a N dimensions space using PCA. <=0, do nothing.
#pcaDimension=0.95
####### k-mean parameters #######
## if run k-mean or not
#runKmeans=true
## the start/end/step point of the k (cluster number)
#k_start=10
#k_end=150
#k_step=5
## the maximum of iteration of the k-mean algorithm if it is not convergent
#maxIterations=1000
## run the following number of times for every k, and take the least cost one
#runs=10
#  # the top semantic type we make it as features; only for 'getUmlsScore' function, not 'select'
#  # for chv paper
semanticType=T204,T007,T200,T061,T109,T002,T121,T116,T033,T004,T201,T023,T028,T123,T047,T074,T037,T060,T126,T013,T129,T044,T170,T191,T029,T059,T043,T005,T012,T114,T015,T130,T058,T014,T030,T046,T081,T011,T019,T026,T131,T167,T097,T197,T024,T195,T025,T192,T073,T034,T040,T122,T203,T083,T042,T082,T045,T048,T184,T080,T169,T194,T168,T078,T079,T125,T098,T020,T039,T190,T093,T031,T196,T049,T067,T038,T127,T062,T171,T185,T041,T091,T032,T018,T054,T055,T070,T057,T077,T065,T090,T068,T089,T064,T022,T056,T092,T104,T052,T099,T063,T086,T101,T120,T087,T051,T017,T102,T066,T001,T008,T016,T100,T075,T050,T069,T096,T095,T053,T072,T094,T010,T103,T071,T085,T021,T088
#  # for clinical trails pattern paper
#  # filter the semantic type by a regular expression. tag extraction function.
sabFilter=SNOMEDCT_US|CHV
#sabFilter=.*
# save the above showing ngram to file
saveNgram2file=C:/fsu/ra/data/orgGram.txt





#######################################################################
############### Output configuration ##################################
# output normalized text for word2vex
#show original ngram before training
showOrgNgramNum=1000000
# shown ngram filter based on N
showOrgNgramOfN=1,2,3,4,5
# shown ngram filter based on pos tagger
showOrgNgramOfPosRegex=.*
# shown ngram filter based on text
showOrgNgramOfTextRegex=.*
# show the number of ngram in every cluster. <0, show nothing
showNgramInCluster=0
#show the average and standard deviation of tf in clusters. Not configurable, always true
#showTfAvgSdInCluster=true
#how many percent of ngram is shown the detail after rank. it show info of every ngram in this top ${showDetailRankPt} percent; <0 don't show detail;
showDetailRankPt=0
# if a Ngram math this filter(regex), the detail information will output to console..
debugFilterNgram=aaaaaaaaaaaaaaaaaa










