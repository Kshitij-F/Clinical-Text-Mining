#  ############# UMLS term matching configuration #####################3
#  # jdbcDriver is the database url that uses for extern info for a term in UMLS. e.g. selecting TUI by CUI from the table MRSTY.
#  # for now, table mrstr is neccessary
 jdbcDriver=jdbc:mysql://localhost:3306/umls?user=root&password=root

useStanfordNLP=true
#lvgdir=/data/ra/lvg2015/
memcached=127.0.0.1:11211

#####*_*####get the training data from (previous save) file, do not construct the Ngram again.
clusteringFromFile=false
# read text from files of a directory, instead of from database
textFromDirectory=true
# the directory of files, if textFromDirectory = true
textDirectory=C:\\fsu\\ra\\wikiextractor\\wiki-test\\AA
# save ngram result to a file.
ngramSaveFile=c:\\fsu\\ra\\data\\ngram_wiki.serd

#  # 0 - 100. if the similarity score for a ngram is greater than this threshold, the ngran will be consider as umls term
umlsLikehoodLimit=50
#  # the window length to fetch context of a ngram
#  WinLen=10
#max length of ngram
ngramN=3
ngramKeepSentence=false

# pos tagger filter (remove the matched item). 1: no noun; 2: ^N+P+N 3: not end with N
# 1. we care NGAW; 2 if more then 2 grams, must ended with NG.
posFilterRegex=[^NGAW]* [^N]*PN .*[^NAGW]$ .+[^NG]$

#######################################################################
############### Ngram relative configuration ###################################
preferLongTermTfRatio=0.5
# the threshold of tf when fetch ngram in partition
partitionTfFilter=2
# when reach this number of ngram in this partition, start to reduce ngram
partitionReduceStartPoint=100000
# each time this number of new ngram in this partition, after start point, reduce ngram
partitionReduceStartStep=10000
# At lease try to reduce how many ngram, fraction of 'stage1ReduceStartStep'
partitionReduceFraction=0.01
# the threshold of tf when fetch ngram in first stage
stag1TfFilter=2
stag1CvalueFilter=1
# the threshold of tf when fetch ngram in second stage
stag2TfFilter=10
stag2CvalueFilter=1
# the thresholh of umls/chv score. no filter if it is -1
stag2UmlsScoreFilter=-1
stag2ChvScoreFilter=-1


######################## bags of words configuration ##############
bagsOfWord=false
bowUmlsOnly=false
bowTfFilter=100
# maximum number of bag of words
bowTopNgram=10000
bowDialogSetOne=false
######################## end of bags of words configuration ######

#######################################################################
############# Clustering relative configuration ##########################
# Nlp do not allow multi-thread, so you can not use local[N] for generating Ngram, but you can use it to run kmeans
sparkMaster=local[4]
partitionNumber=8
repartitionForce=true
########### only use chv term as trainig data
trainOnlyChv=true
# filter the ngran before run kmeans (remove the matched item)
trainedNgramFilterPosRegex=[^N]*PN
# how many percent of the data is sample as test data(for evaluation), <= 0, no thing is test
testSample=30
sampleRuns=1
#number of ngram for training. For test purpose. <0: no limit;
trainNgramCnt=-1

# PCA only. Compact the feature space matrix to a N dimensions space using PCA. <=0, do nothing.
pcaDimension=0.95
###### k-mean parameters #######
# if run k-mean or not
runKmeans=true
# the start/end/step point of the k (cluster number)
k_start=50
k_end=51
k_step=5
# the maximum of iteration of the k-mean algorithm if it is not convergent
maxIterations=1000
# run the following number of times for every k, and take the least cost one
runs=10
#  # the top semantic type we make it as features; only for 'getUmlsScore' function, not 'select'
#  # all sty
semanticType=T116,T020,T052,T100,T087,T011,T190,T008,T017,T195,T194,T123,T007,T031,T022,T053,T038,T012,T029,T091,T122,T023,T030,T118,T026,T043,T025,T019,T103,T120,T104,T185,T201,T200,T077,T049,T088,T060,T056,T203,T047,T065,T069,T111,T196,T050,T018,T071,T126,T204,T051,T099,T021,T013,T033,T004,T168,T169,T045,T083,T028,T064,T102,T096,T068,T093,T058,T131,T125,T016,T078,T129,T055,T197,T037,T170,T130,T171,T059,T034,T119,T015,T063,T066,T074,T041,T073,T048,T044,T085,T191,T114,T070,T124,T086,T057,T090,T115,T109,T032,T040,T001,T092,T042,T046,T072,T067,T039,T121,T002,T101,T098,T097,T094,T080,T081,T192,T014,T062,T075,T089,T167,T095,T054,T184,T082,T110,T024,T079,T061,T005,T127,T010
#  # for clinical trails pattern paper
#  # filter the semantic type by a regular expression. tag extraction function.
#  #sabFilter=SNOMEDCT_US|NCI|GO
 sabFilter=.*
# save the above showing ngram to file
saveNgram2file=

#######################################################
############### Output configuration ##################################
# output normalized text for word2vex
#show original ngram before training
showOrgNgramNum=100
# shown ngram filter based on N
showOrgNgramOfN=1,2,3,4,5
# shown ngram filter based on pos tagger
showOrgNgramOfPosRegex=.*
# shown ngram filter based on text
showOrgNgramOfTextRegex=.*
# show the number of ngram in every cluster. <0, show nothing
showNgramInCluster=0
#show the average and standard deviation of tf in clusters. Not configurable, always true
#showTfAvgSdInCluster=true
#how many percent of ngram is shown the detail after rank. it show info of every ngram in this top ${showDetailRankPt} percent; <0 don't show detail;
showDetailRankPt=0
# if a Ngram math this filter(regex), the detail information will output to console..
debugFilterNgram=aaaaaaaaaaaaaaaaaa






