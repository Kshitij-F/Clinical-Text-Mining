###########################################################3333333333
############# UMLS term matching configuration #####################3
# jdbcDriver is the database url that uses for selecting TUI by CUI from the table MRSTY.
jdbcDriver=jdbc:mysql://localhost:3306/umls?user=root&password=root
#url of solr we use to match umls term
solrServerUrl=http://localhost:8983/solr

# caseFactor is [0, 1] value. It indicates how much you concern the case. It will affect the score
# when you select a term from solr. Value 0 means upcase and lowcase are totally different, and
# value 1 means upcase and lowcase are not different at all.
caseFactor=0.8

#Should we take the newline as the end of a sentence? or just ignore the newline?
#  1: replace with space; 2: replace with '.'; 0: do nothing
ignoreNewLine=2


#######################################################################3
########## data source to fetching configuration ######################3
# how to get the text to get Ngram; the blogId will select as distict, and the blogTextCol will be limit to 1 row.
blogDbUrl=jdbc:mysql://localhost:3306/ytex?user=root&password=root
#blogTbl=org_yahoo
blogTbl=content_org_new
#blogIdCol=id
blogIdCol=blogId
#blogTextCol=concat(subject, ". ", content, ". ", chosenanswer)
blogTextCol=text_content

# limit the blog to be analyzed, mainly for test
blogLimit=10000000

#######################################################################
################### NLP relative configuration ###############################
#root dir of lvg
lvgdir=C:\\fsu\\ra\\UmlsTagger\\lvg2015\\

# include POS tagger. The Ngram (basic terms) have to contain at least one of those POS tagger. it also the definition of 'noun' in this tool.
posInclusive=NN NNS NNP NNPS
# 0 - 100
umlsLikehoodLimit=30
# the window length to fetch context of a ngram
WinLen=10

# use to force delimit gram. Delimiter = Pattern.compile("[,;/\\:\\(\\)\\[\\]\\{\\}\"]+")
delimiter =[,;/\\:\\(\\)\\[\\]\\{\\}\"]+

# how does ngram  match the stop words list? 0:exactly matching; 1: ngram contains any stop word; 2: ngram start or end with any stop word; others: no filter
stopwordMatchType=2

# besides the file of stop word, you can specify a regex to indicate what is a stop word.
# exclude the gram start with digital or only digital. (remove the matched item)
stopwordRegex=^\\d+($|(\\s+.*))
# pos tagger filter (remove the matched item). 1: no noun; 2: ^N+P+N 3: not end with N
#posFilterRegex=[^N]* [^N]*PN .*[^N]$
posFilterRegex=[^N]*

#######################################################################
############### Ngram relative configuration ###################################
# the threshold of tf when fetch ngram in partition
partitionTfFilter=2
# the threshold of tf when fetch ngram in first stage
stag1TfFilter=2
stag1CvalueFilter=1
# the threshold of tf when fetch ngram in second stage
stag2TfFilter=2
stag2CvalueFilter=1

# if any of this greater than 0, it will rank the ngram, and take the top N.
# this configuration can affect bags of words function.
topTfNgram=0
topCvalueNgram=0
topTfdfNgram=0

######################## bags of words configuration ###############
bagsOfWord=false
bowTopCvalueNgram=10000
######################## end of bags of words configuration ######

#######################################################################
############# Clustering relative configuration ##########################
# Nlp do not allow multi-thread, so you can not use local[N] for generating Ngram, but you can use it to run kmeans
sparkMaster=local[2]
partitionNumber=2

#####*_*####get the training data from (previous save) file, do not construct the Ngram again.
clusteringFromFile=true
ngramSaveFile=c:\\fsu\\ra\\data\\ngram_all_0129.serd.no_bow
# only use chv term as trainig data
trainOnlyChv=true
# filter the ngran before run kmeans (remove the matched item)
trainedNgramFilterPosRegex=[^N]*PN

# how many percent of the data is sample as test data(for evaluation), <= 0, no thing is test
testSample=-1
sampleRuns=1
#number of ngram for training. For test purpose. <0: no limit;
trainNgramCnt=-1
# if normalized the feature to [0,1] range. see https://en.wikipedia.org/wiki/Feature_scaling
# Rescaling or Standardization
normalizeFeature=true
normalize_rescale=true
normalize_standardize=false
# generate feature vectors only. So you can use the vectors in R or other tools.
outputVectorOnly=false
# PCA only. Compact the feature space matrix to a N dimensions space using PCA. <=0, do nothing.
pcaDimension=0


# the feature used in kmeans
#           tfdf,cvalue,umls_score,chv_score,contain_umls,contain_chv,win_umls,win_chv,sent_umls,sent_chv,umls_dist,chv_dist,nn,an,pn,anpn,stys,win_pos,capt_first,capt_all,capt_term
useFeatures4Train=tfdf:0.5,cvalue:0.5,umls_score:0.5,chv_score:0,contain_umls:1,contain_chv:1,nn,an,pn,anpn,stys:0,win_pos,capt_first,capt_all,capt_term,prefix:1,suffix:1,win_umls,win_chv,sent_umls,sent_chv,umls_dist,chv_dist
useFeatures4Test =tfdf:0.5,cvalue:0.5,umls_score:0.5,chv_score:0,contain_umls:1,contain_chv:1,nn,an,pn,anpn,stys:0,win_pos,capt_first,capt_all,capt_term,prefix:1,suffix:1,win_umls,win_chv,sent_umls,sent_chv,umls_dist,chv_dist
#useFeatures4Train=tfdf,cvalue,umls_score,chv_score,contain_umls,contain_chv,nn,an,pn,anpn,stys,win_pos,capt_first,capt_all,capt_term,prefix,suffix,win_umls,win_chv,sent_umls,sent_chv,umls_dist,chv_dist
#useFeatures4Test =tfdf,cvalue,umls_score,chv_score,contain_umls,contain_chv,nn,an,pn,anpn,stys,win_pos,capt_first,capt_all,capt_term,prefix,suffix,win_umls,win_chv,sent_umls,sent_chv,umls_dist,chv_dist


# the top semantic type we make it as features
semanticType=T033,T121,T061,T047,T109,T023,T184,T074,T116,T123,T059,T046
# the syntax that occur around a ngram in a window. they have been transformed to a single character
posInWindown=CMDEFPANURTVO
# prefix/suffix use window or only process ngram itself
prefixSuffixUseWindow=false
tfdfLessLog=false

###### k-mean parameters #######
# if run k-mean or not
runKmeans=true
# the start/end/step point of the k (cluster number)
k_start=50
k_end=50
k_step=5
# the maximum of iteration of the k-mean algorithm if it is not convergent
maxIterations=1000
# run the following number of times for every k, and take the least cost one
runs=10
# if remove these clusters that contain too small number of points.
reviseModel=true
# how many percent of the training data does a cluster at least contain (compare to the average number of ngram in a cluster. ?
clusterThresholdPt=10
# get the score for every K(number of cluster), and then we can choose a 'best' K.
#see:https://en.wikipedia.org/wiki/Silhouette_(clustering)
clusterScore=false
#######################################
### Ranking relative configuration ###
# get the baseline result( rank on tfall and cvlaue)
baseLineRank=false
runRank=true
# the granular of rank (percent), e.g. rankGranular=5 work as 5%, 10%, 15%,
rankGranular=5
# since rank are based on percentage of ngram, this parameter specify the base number to calculate the percentage.
# percentage = (# of current ngram)/rankLevelBase, -1: use number of tested ngram if testSample>0, or use number of all ngram
rankLevelBase=1000
# specify how many level of percentage, e.g. 4 means 5%,10%,15%,20%, the percentage may be greater than 100%
rankLevelNumber=20

# the beta value for evaluating f-score, see:https://en.wikipedia.org/wiki/F1_score
# Two other commonly used F measures are the F_{2} measure, which weights recall higher than precision,
#and the F_{0.5} measure, which puts more emphasis on precision than recall.
fscoreBeta=0.5

# no use for now
rankWithTrainData=false

#######################################################################
############### Output configuration ##################################
#show original ngram before training
showOrgNgramNum=10
# shown ngram filter based on N
showOrgNgramOfN=1,2,3,4,5
# shown ngram filter based on pos tagger
showOrgNgramOfPosRegex=.*
# shown ngram filter based on text
showOrgNgramOfTextRegex=.*
# show the number of ngram in every cluster. <0, show nothing
showNgramInCluster=-1
#how many percent of ngram is shown the detail after rank. it show info of every ngram in this top ${showDetailRankPt} percent; <0 don't show detail;
showDetailRankPt=100
# if a Ngram math this filter(regex), the detail information will output to console..
debugFilterNgram=aaaaaaaaaaaaaaaaaa
